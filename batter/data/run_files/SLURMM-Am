#!/bin/bash

#SBATCH --job-name="SYSTEMNAME-STAGE-POSE"
#SBATCH --partition=PARTITIONNAME
#SBATCH --nodes=1
#SBATCH --open-mode=append
#SBATCH --output=STAGE-POSE-%j.out
#SBATCH --error=STAGE-POSE-%j.err
#SBATCH --gres=gpu:1
#SBATCH --ntasks=1
#SBATCH -t 16:00:00
#SBATCH -d singleton

scontrol show job $SLURM_JOB_ID

OVERWRITE=${OVERWRITE:-0}  # Default to 0 if not set

# Set a path for the retry count file on a shared filesystem.
# Change this path as needed.
ATTEMPT_FILE="job_attempt.txt"

# Initialize the attempt count file if it doesn't exist.
if [ ! -f "$ATTEMPT_FILE" ]; then
    echo "1" > "$ATTEMPT_FILE"
fi

# Read the current retry count.
RETRY_COUNT=$(cat "$ATTEMPT_FILE")
echo "Current attempt: $RETRY_COUNT"

# Define the maximum number of attempts.
MAX_ATTEMPTS=3

source $GROUP_HOME/software/amber24/setup_amber.sh > /dev/null 2>&1

# Run the simulation
echo "Attempt $RETRY_COUNT to run simulations..."
OVERWRITE=$OVERWRITE source run-local.bash 2>&1 | tee run.log
error_code=${PIPESTATUS[0]}  # Capture the exit status of 'source run-local.bash'

if [ $error_code -eq 0 ]; then
    echo "Simulation completed successfully on attempt $RETRY_COUNT."
else
    echo "Simulation failed with error code $error_code on attempt $RETRY_COUNT."

    if [ $RETRY_COUNT -lt $MAX_ATTEMPTS ]; then
        NEXT_RETRY=$((RETRY_COUNT + 1))
        # Update the file with the new retry count.
        echo "$NEXT_RETRY" > "$ATTEMPT_FILE"
        echo "Requeuing the job for attempt $NEXT_RETRY..."
        # Requeue the same job (retains the same job ID).
        scontrol requeue $SLURM_JOB_ID
        exit 0
    else
        echo "FAILED" > FAILED
        echo "Maximum attempts ($MAX_ATTEMPTS) reached. Simulation failed."
        exit 1
    fi
fi

# write FINISHED to a file
echo "FINISHED" > FINISHED
exit 0