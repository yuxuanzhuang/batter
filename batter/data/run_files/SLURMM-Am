#!/bin/bash

#SBATCH --job-name="SYSTEMNAME-STAGE-POSE"
#SBATCH --partition=PARTITIONNAME
#SBATCH --nodes=1
#SBATCH --output=STAGE-POSE-%j.out
#SBATCH --error=STAGE-POSE-%j.err
#SBATCH --gres=gpu:1
#SBATCH --ntasks=1
#SBATCH -t 8:00:00
#SBATCH -d singleton

scontrol show job $SLURM_JOB_ID

# Define the retry count and overwrite variables
RETRY_COUNT=${RETRY_COUNT:-1}  # Default to 1 if not set
OVERWRITE=${OVERWRITE:-1}  # Default to 1 if not set

# if requeue, set overwrite to 0
if [ -n "$SLURM_REQUEUE" ]; then
    OVERWRITE=0
fi

echo "RETRY_COUNT=$RETRY_COUNT, OVERWRITE=$OVERWRITE"

trap cleanup SIGTERM SIGINT SIGUSR1
 
source $GROUP_HOME/software/amber24/setup_amber.sh > /dev/null 2>&1

# Define the maximum number of attempts
MAX_ATTEMPTS=3

# Run the simulation
echo "Attempt $RETRY_COUNT to run simulations..."
OVERWRITE=$OVERWRITE source run-local.bash 2>&1 | tee run.log
error_code=${PIPESTATUS[0]}  # Capture the exit status of 'source run-local.bash'

if [ $error_code -eq 0 ]; then
    echo "Simulation completed successfully on attempt $RETRY_COUNT."
else
    echo "Simulation failed with error code $error_code on attempt $RETRY_COUNT."

    # Check if the maximum attempts have been reached
    if [ $RETRY_COUNT -lt $MAX_ATTEMPTS ]; then
        NEXT_RETRY=$((RETRY_COUNT + 1))
        echo "Resubmitting the job for attempt $NEXT_RETRY..."
        # Submit the same script with an incremented retry count
        sbatch --export=RETRY_COUNT=$NEXT_RETRY,OVERWRITE=1 $0
        exit 0
    else
        echo "FAILED" > FAILED
        echo "Maximum attempts ($MAX_ATTEMPTS) reached. Simulation failed."
        exit 1
    fi
fi

# write FINISHED to a file
echo "FINISHED" > FINISHED
exit 0